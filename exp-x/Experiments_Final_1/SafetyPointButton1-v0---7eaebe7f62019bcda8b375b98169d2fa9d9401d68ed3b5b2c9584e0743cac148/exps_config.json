
{
    "seed": 0,
    "train_cfgs": {
        "total_steps": 600000,
        "torch_threads": 8,
        "vector_env_nums": 4,
        "device": "cuda:0"
    },
    "algo_cfgs": {
        "steps_per_epoch": 20000
    },
    "logger_cfgs": {
        "wandb_project": "Experiments_Final",
        "use_wandb": true,
        "log_dir": "./exp-x\\Experiments_Final_1\\SafetyPointButton1-v0---7eaebe7f62019bcda8b375b98169d2fa9d9401d68ed3b5b2c9584e0743cac148\\"
    },
    "algo": "PPO",
    "env_id": "SafetyPointButton1-v0"
}